{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\basel\\OneDrive\\سطح المكتب\\non\\Social Network Task\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: 6 nodes, 7 features\n",
            "Train: 2, Test: 4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "from improved_gcn import prepare_data, ImprovedGCN, train_model\n",
        "\n",
        "# Load and prepare data\n",
        "data = prepare_data()\n",
        "print(f\"Data: {data.num_nodes} nodes, {data.num_node_features} features\")\n",
        "print(f\"Train: {data.train_mask.sum()}, Test: {data.test_mask.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class SimpleGCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_features, 4)\n",
        "        self.conv2 = GCNConv(4, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Original Simple GCN ===\n",
            "Simple GCN Accuracy: 1.0000\n",
            "\n",
            "=== Improved GCN ===\n",
            "Epoch 000, Loss: 0.6847, Test Acc: 0.5000\n",
            "Epoch 050, Loss: 0.1133, Test Acc: 1.0000\n",
            "Epoch 100, Loss: 0.0229, Test Acc: 1.0000\n",
            "Epoch 150, Loss: 0.0116, Test Acc: 1.0000\n",
            "Early stopping at epoch 153\n",
            "Improved GCN Accuracy: 1.0000\n",
            "\n",
            "Improvement: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Original simple model\n",
        "print(\"=== Original Simple GCN ===\")\n",
        "model_simple = SimpleGCN(data.num_node_features, 2)\n",
        "optimizer = torch.optim.Adam(model_simple.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    model_simple.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model_simple(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "model_simple.eval()\n",
        "pred_simple = model_simple(data).argmax(dim=1)\n",
        "acc_simple = (pred_simple[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
        "print(f'Simple GCN Accuracy: {acc_simple:.4f}')\n",
        "\n",
        "# Improved model\n",
        "print(\"\\n=== Improved GCN ===\")\n",
        "model_improved = ImprovedGCN(num_features=data.num_node_features, num_classes=2)\n",
        "model_improved = train_model(model_improved, data)\n",
        "\n",
        "model_improved.eval()\n",
        "pred_improved = model_improved(data).argmax(dim=1)\n",
        "acc_improved = (pred_improved[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
        "print(f'Improved GCN Accuracy: {acc_improved:.4f}')\n",
        "\n",
        "print(f\"\\nImprovement: {acc_improved - acc_simple:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTE: Accuracy 100% because data set very small  , we can test harder dataset like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing with Realistic Data ===\n",
            "Realistic data: 12 nodes\n",
            "Train: 8, Test: 4\n",
            "Graph density: 0.258\n",
            "Epoch 000, Loss: 0.7361, Test Acc: 0.0000\n",
            "Epoch 050, Loss: 0.6244, Test Acc: 1.0000\n",
            "Epoch 100, Loss: 0.5659, Test Acc: 0.7500\n",
            "Epoch 150, Loss: 0.5300, Test Acc: 1.0000\n",
            "Early stopping at epoch 175\n",
            "\n",
            "Realistic Test Accuracy: 0.7500\n",
            "This is more representative of real-world performance!\n",
            "\n",
            "Predictions vs Actual:\n",
            "Node 4: Predicted 0, Actual 0 ✓\n",
            "Node 5: Predicted 0, Actual 0 ✓\n",
            "Node 10: Predicted 0, Actual 1 ✗\n",
            "Node 11: Predicted 1, Actual 1 ✓\n"
          ]
        }
      ],
      "source": [
        "# realistic_test\n",
        "import networkx as nx\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from improved_gcn import ImprovedGCN, train_model, enhance_features\n",
        "import random\n",
        "\n",
        "def create_realistic_data():\n",
        "    \"\"\"Create a more realistic social network with some overlap\"\"\"\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Create communities with some connections between them\n",
        "    edges = [\n",
        "        # Normal user community (0-5)\n",
        "        (0,1), (1,2), (2,0), (3,4), (4,5), (5,3), (1,3),\n",
        "\n",
        "        # Bot community (6-11)\n",
        "        (6,7), (7,8), (8,6), (9,10), (10,11), (11,9), (7,9),\n",
        "\n",
        "        # Some cross-connections (bots connecting to normal users)\n",
        "        (6,2),  # bot 6 follows normal user 2\n",
        "        (10,4), # bot 10 follows normal user 4\n",
        "        (8,1),  # bot 8 follows normal user 1\n",
        "    ]\n",
        "\n",
        "    G.add_edges_from(edges)\n",
        "\n",
        "    # Features: one-hot + random noise (more realistic)\n",
        "    num_nodes = 12\n",
        "    features = torch.eye(num_nodes, dtype=torch.float)\n",
        "    # Add some noise to simulate real-world data\n",
        "    noise = torch.randn(num_nodes, num_nodes) * 0.1\n",
        "    features = features + noise\n",
        "\n",
        "    # Labels: first 6 normal (0), last 6 bots (1)\n",
        "    labels = torch.tensor([0,0,0,0,0,0, 1,1,1,1,1,1], dtype=torch.long)\n",
        "\n",
        "    # Convert to PyG Data\n",
        "    edge_index = torch.tensor(list(G.edges())).t().contiguous()\n",
        "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
        "    data = Data(x=features, edge_index=edge_index, y=labels)\n",
        "\n",
        "    # Enhanced features\n",
        "    data.x = enhance_features(data)\n",
        "\n",
        "    # Balanced train/test split\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    # Train on 4 from each class, test on 2 from each class\n",
        "    train_indices = [0,1,2,3, 6,7,8,9]    # 4 normal + 4 bots\n",
        "    test_indices = [4,5, 10,11]           # 2 normal + 2 bots\n",
        "\n",
        "    train_mask[train_indices] = True\n",
        "    test_mask[test_indices] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "def test_with_noise():\n",
        "    \"\"\"Test with noisy labels (some mislabeled nodes)\"\"\"\n",
        "    data = create_realistic_data()\n",
        "\n",
        "    # Simulate real-world noise: mislabel 2 nodes\n",
        "    noisy_labels = data.y.clone()\n",
        "    noisy_labels[2] = 1  # Normal user mislabeled as bot\n",
        "    noisy_labels[7] = 0  # Bot mislabeled as normal\n",
        "    data.y = noisy_labels\n",
        "\n",
        "    print(f\"Realistic data: {data.num_nodes} nodes\")\n",
        "    print(f\"Train: {data.train_mask.sum()}, Test: {data.test_mask.sum()}\")\n",
        "    print(f\"Graph density: {len(data.edge_index[0])/(data.num_nodes*(data.num_nodes-1)):.3f}\")\n",
        "\n",
        "    # Test Improved GCN\n",
        "    model = ImprovedGCN(num_features=data.num_node_features, num_classes=2, hidden_dim=16)\n",
        "    model = train_model(model, data, epochs=300)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(data).argmax(dim=1)\n",
        "        acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
        "\n",
        "    print(f'\\nRealistic Test Accuracy: {acc:.4f}')\n",
        "    print(\"This is more representative of real-world performance!\")\n",
        "\n",
        "    # Show predictions vs actual\n",
        "    print(\"\\nPredictions vs Actual:\")\n",
        "    for i in range(data.num_nodes):\n",
        "        if data.test_mask[i]:\n",
        "            status = \"✓\" if pred[i] == data.y[i] else \"✗\"\n",
        "            print(f\"Node {i}: Predicted {pred[i].item()}, Actual {data.y[i].item()} {status}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Testing with Realistic Data ===\")\n",
        "    test_with_noise()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
